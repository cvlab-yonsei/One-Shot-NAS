{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13077750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, glob, random, argparse\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import scipy.stats as stats\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "from xautodl.config_utils import load_config, dict2config, configure2str\n",
    "from xautodl.datasets import get_datasets, get_nas_search_loaders\n",
    "from xautodl.procedures import (\n",
    "    prepare_seed,\n",
    "    prepare_logger,\n",
    "    save_checkpoint,\n",
    "    copy_checkpoint,\n",
    "    get_optim_scheduler,\n",
    ")\n",
    "from xautodl.utils import get_model_infos, obtain_accuracy\n",
    "from xautodl.log_utils import AverageMeter, time_string, convert_secs2time\n",
    "from xautodl.models import get_cell_based_tiny_net, get_search_spaces\n",
    "from nas_201_api import NASBench201API as API\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\"  # Set the GPU 2 to use\n",
    "os.chdir('../../')\n",
    "api = API('nasbench201/NAS-Bench-201-v1_1-096897.pth')\n",
    "\n",
    "# file_name = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 250\n",
    "\n",
    "\n",
    "search_space = get_search_spaces(\"cell\", 'nas-bench-201')\n",
    "model_config = dict2config(\n",
    "    {\n",
    "        \"name\": \"RANDOM\",\n",
    "        \"C\": 16,\n",
    "        \"N\": 5,\n",
    "        \"max_nodes\": 4,\n",
    "        \"num_classes\": 10,\n",
    "        \"space\": search_space,\n",
    "        \"affine\": False,\n",
    "        \"track_running_stats\": bool(0),\n",
    "    },\n",
    "    None,\n",
    ")\n",
    "\n",
    "supernet_config = dict2config(\n",
    "    {\n",
    "        \"name\": \"supernet\",\n",
    "        \"C\": 16,\n",
    "        \"N\": 5,\n",
    "        \"max_nodes\": 4,\n",
    "        \"num_classes\": 10,\n",
    "        \"space\": search_space,\n",
    "        \"affine\": False,\n",
    "        \"track_running_stats\": bool(0),\n",
    "    },\n",
    "    None,\n",
    ")\n",
    "\n",
    "def distill(result):\n",
    "    result = result.split('\\n')\n",
    "    cifar10 = result[5].replace(' ', '').split(':')\n",
    "    cifar100 = result[7].replace(' ', '').split(':')\n",
    "    imagenet16 = result[9].replace(' ', '').split(':')\n",
    "\n",
    "    cifar10_train = float(cifar10[1].strip(',test')[-7:-2].strip('='))\n",
    "    cifar10_test = float(cifar10[2][-7:-2].strip('='))\n",
    "    cifar100_train = float(cifar100[1].strip(',valid')[-7:-2].strip('='))\n",
    "    cifar100_valid = float(cifar100[2].strip(',test')[-7:-2].strip('='))\n",
    "    cifar100_test = float(cifar100[3][-7:-2].strip('='))\n",
    "    imagenet16_train = float(imagenet16[1].strip(',valid')[-7:-2].strip('='))\n",
    "    imagenet16_valid = float(imagenet16[2].strip(',test')[-7:-2].strip('='))\n",
    "    imagenet16_test = float(imagenet16[3][-7:-2].strip('='))\n",
    "\n",
    "    return cifar10_train, cifar10_test, cifar100_train, cifar100_valid, \\\n",
    "        cifar100_test, imagenet16_train, imagenet16_valid, imagenet16_test\n",
    "\n",
    "search_model = get_cell_based_tiny_net(model_config)\n",
    "supernet = get_cell_based_tiny_net(supernet_config)\n",
    "supernet = supernet.cuda()\n",
    "optimizer = torch.optim.SGD(\n",
    "    params = search_model.parameters(),\n",
    "    lr = 0.025,\n",
    "    momentum = 0.9,\n",
    "    weight_decay = 0.0005,\n",
    "    nesterov = True \n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max = epochs,\n",
    "    eta_min = 0.001\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "network = search_model.cuda()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "train_data, valid_data, _, _ = get_datasets(\n",
    "        'cifar10', './dataset', -1\n",
    "    )\n",
    "\n",
    "search_loader, _, _ = get_nas_search_loaders( \n",
    "        train_data,                                      \n",
    "        valid_data,                                     \n",
    "        'cifar10',\n",
    "        \"configs/nas-benchmark/\",\n",
    "        (64, 256), \n",
    "        4,\n",
    "    )\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "            valid_data,\n",
    "            batch_size=256,\n",
    "            shuffle = False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "from xautodl.models.cell_searchs.genotypes import Structure\n",
    "\n",
    "genotypes = []\n",
    "op_names = deepcopy(search_space)\n",
    "for i in range(1, 4):\n",
    "    xlist = []\n",
    "    for j in range(i):\n",
    "        op_name = random.choice(op_names)\n",
    "        xlist.append((op_name, j))\n",
    "    genotypes.append(tuple(xlist))\n",
    "arch = Structure(genotypes)\n",
    "\n",
    "edge2index = network.edge2index\n",
    "max_nodes = 4\n",
    "def genotype(enc): \n",
    "    theta = enc\n",
    "    genotypes = []\n",
    "    for i in range(1, max_nodes):\n",
    "      xlist = []\n",
    "      for j in range(i):\n",
    "        node_str = '{:}<-{:}'.format(i, j)\n",
    "        with torch.no_grad():\n",
    "          weights = theta[ edge2index[node_str] ]\n",
    "          op_name = op_names[ weights.argmax().item() ]\n",
    "        xlist.append((op_name, j))\n",
    "      genotypes.append( tuple(xlist) )\n",
    "    return Structure( genotypes )\n",
    "\n",
    "\n",
    "struc = []\n",
    "base = torch.zeros(6,5)\n",
    "for i in range(5):   \n",
    "    base[0,i] = 1\n",
    "    \n",
    "    for ii in range(5):\n",
    "        base[1,ii] = 1     \n",
    "        \n",
    "        for iii in range(5):\n",
    "            base[2,iii]=1\n",
    "            \n",
    "            for j in range(5):\n",
    "                base[3,j] = 1\n",
    "                \n",
    "                for jj in range(5):\n",
    "                    base[4,jj] = 1\n",
    "                    \n",
    "                    for jjj in range(5):\n",
    "                        base[5,jjj] = 1\n",
    "                        \n",
    "                        struc.append(base.clone())\n",
    "                       \n",
    "                        \n",
    "                        base[5] = 0\n",
    "                    base[4] = 0\n",
    "                base[3] = 0\n",
    "            base[2] = 0\n",
    "        base[1] = 0\n",
    "    base[0] = 0\n",
    "    \n",
    "def get_num_params(result):\n",
    "    result = result.split('\\n')\n",
    "    cifar10 = result[2].split(' ')\n",
    "\n",
    "    return float(cifar10[-4].strip('Params='))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(\"./exps/NAS-Bench-201-algos/kendal_valid_accs/cifar10_accs.pkl\",\"rb\") as f:\n",
    "    cifar10_accs = pickle.load(f)    \n",
    "\n",
    "with open(\"./exps/NAS-Bench-201-algos/kendal_valid_accs/cifar100_accs.pkl\",\"rb\") as f:\n",
    "    cifar100_accs = pickle.load(f)    \n",
    "\n",
    "with open(\"./exps/NAS-Bench-201-algos/kendal_valid_accs/imagenet_accs.pkl\",\"rb\") as f:\n",
    "    imagenet_accs = pickle.load(f)  \n",
    "    \n",
    "with open(\"./exps/NAS-Bench-201-algos/kendal_valid_accs/num_params.pkl\",\"rb\") as f:\n",
    "    num_params = pickle.load(f)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "low_param_val = 0.344\n",
    "high_param_val = 0.343\n",
    "\n",
    "print(low_param_val, high_param_val)\n",
    "\n",
    "def analysis(file_name):\n",
    "    \n",
    "    print(f'===============  {file_name}  ===============')\n",
    "    with open(f\"./exps/NAS-Bench-201-algos/kendal_valid_accs/{file_name}.pkl\",\"rb\") as f:\n",
    "        valid_accs = pickle.load(f)\n",
    "    cifar10_valid_true_tau, _ = stats.kendalltau(valid_accs, cifar10_accs)     \n",
    "    cifar100_valid_true_tau, _ = stats.kendalltau(valid_accs, cifar100_accs)   \n",
    "    imagenet_valid_true_tau, _ = stats.kendalltau(valid_accs, imagenet_accs) \n",
    "\n",
    "    cifar10_true_valid_tau, _ = stats.kendalltau(cifar10_accs, valid_accs)   \n",
    "    cifar100_true_valid_tau, _ = stats.kendalltau(cifar100_accs, valid_accs)  \n",
    "    imagenet_true_valid_tau, _ = stats.kendalltau(imagenet_accs, valid_accs)\n",
    "\n",
    "    print(f'cifar10_valid_true_tau: {cifar10_valid_true_tau}')\n",
    "    print(f'cifar100_valid_true_tau: {cifar100_valid_true_tau}')\n",
    "    print(f'imagenet_valid_true_tau: {imagenet_valid_true_tau}')\n",
    "\n",
    "    print(f'param vs valid_accs: {stats.kendalltau(valid_accs, num_params) }')\n",
    "    low_param = []\n",
    "    low_param_valid = []\n",
    "    low_param_real = []\n",
    "\n",
    "    for i in range(len(num_params)):\n",
    "        if num_params[i] < float(low_param_val):\n",
    "            low_param.append(num_params[i])\n",
    "            low_param_valid.append(valid_accs[i])\n",
    "            low_param_real.append(cifar10_accs[i])\n",
    "\n",
    "    print(f'low_param_kendal: {stats.kendalltau(low_param_valid, low_param_real)}')\n",
    "\n",
    "    high_param = []\n",
    "    high_param_valid = []\n",
    "    high_param_real = []\n",
    "\n",
    "    for i in range(len(num_params)):\n",
    "        if num_params[i] > float(high_param_val):\n",
    "            high_param.append(num_params[i])\n",
    "            high_param_valid.append(valid_accs[i])\n",
    "            high_param_real.append(cifar10_accs[i])\n",
    "\n",
    "    print(f'high_param_kendal: {stats.kendalltau(high_param_real, high_param_valid)}')\n",
    "    \n",
    "    print(api.query_by_arch(genotype(struc[np.argmax(np.array(valid_accs))]), '200'))\n",
    "\n",
    "    \n",
    "analysis('baseline_ep_250')\n",
    "print('*********************************************************\\n*********************************************************')\n",
    "analysis('Adaptive_LR_max_coeff_3_log_formulation')\n",
    "print('*********************************************************\\n*********************************************************')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
